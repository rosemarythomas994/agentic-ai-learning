{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6: APIs to use AI models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this lesson, you will learn how to use the OpenAI API. You'll also see how the `print_llm_response` and `get_llm_response` functions you have been using work to pass your prompt to the OpenAI API and retrieve the response.\n",
    "\n",
    "As always, you'll start by loading some functions you need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `openai` package, which you are using for the first time! The `OpenAI` function here is what enables the connect in Python to the chatbot. Check out the [OpenAI documentation](https://platform.openai.com/docs/api-reference/introduction) if you want to learn more!\n",
    "\n",
    "**Note:** If you want to install this on your own computer, you would run `!pip install openai`. But it's already installed here for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#F5C780; padding:15px\"> 🤖 <b>Use the Chatbot</b>: \n",
    "<br><br>\n",
    "Explain what each line of this function does:\n",
    "<br><br>\n",
    "def get_llm_response(prompt):<br>\n",
    "&nbsp &nbsp &nbsp completion = client.chat.completions.create(<br>\n",
    "&nbsp &nbsp &nbsp model=\"gpt-4o-mini\",<br>\n",
    "&nbsp &nbsp &nbspmessages=[<br>\n",
    "&nbsp &nbsp &nbsp&nbsp{<br>\n",
    "&nbsp &nbsp &nbsp&nbsp&nbsp\"role\": \"system\",<br>\n",
    "&nbsp &nbsp &nbsp&nbsp&nbsp\"content\": \"You are a helpful but terse AI assistant who gets straight to the point.\",<br>\n",
    "&nbsp &nbsp &nbsp&nbsp&nbsp},<br>\n",
    "&nbsp &nbsp &nbsp&nbsp{\"role\": \"user\", \"content\": prompt},<br>\n",
    "&nbsp &nbsp &nbsp&nbsp],<br>\n",
    "&nbsp &nbsp &nbsptemperature=0.0,<br>\n",
    "&nbsp &nbsp &nbsp)<br>\n",
    "&nbsp &nbsp &nbspresponse = completion.choices[0].message.content<br>\n",
    "&nbspreturn response<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the API key\n",
    "\n",
    "To use the OpenAI API service you need an API key. Run the following code to set up the key in this learning environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# Get the OpenAI API key from the .env file\n",
    "load_dotenv('.env', override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key = openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting ```get_llm_response```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code you saw in the slides to define the ```get_llm_response``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "def get_llm_response(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI assistant.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use this function to ask a question to an LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "prompt = \"What is the capital of France?\"\n",
    "response = get_llm_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the system message to change the LLM behavior \n",
    "\n",
    "Try changing/adding details in the \"content\" of the system message to change the LLM response\n",
    "* For example, \"You are a sarcastic AI assistant.\"\n",
    "* Be sure to run the function cell each time you change the system message before you prompt the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "def get_llm_response(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI assistant.\", # change this instruction!\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now give your prompt to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the capital of France?\"\n",
    "response = get_llm_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vary the system prompt a few times to see the behavior change!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the temperature to change the randomness of the output\n",
    "\n",
    "Try changing the temperature value to make the response of the model more random and different each time\n",
    "* For example, set the temperature to 1.0 or 0.7 and see what happens\n",
    "* Be sure to run the function cell each time you change the temperature before you prompt the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "def get_llm_response(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI assistant.\", \n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.0, # change this to a value between 0 and 2\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now give your prompt to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the capital of France?\"\n",
    "response = get_llm_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the temperature to a value greater than 0 and run the prompt cell a few times to see the response change!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LLMs through the `aisetup` package\n",
    "\n",
    "If you have installed aisetup on your own computer, you'll need to run an extra line of code to get your own API key into the notebook and accessible to the `print_llm_response` and `get_llm_response` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from aisetup import authenticate, print_llm_response, get_llm_response\n",
    "\n",
    "authenticate(\"YOUR API KEY HERE\")\n",
    "\n",
    "# Print the LLM response\n",
    "print_llm_response(\"What is the capital of France\")\n",
    "\n",
    "# Store the LLM response as a variable and then print\n",
    "response = get_llm_response(\"What is the capital of France\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Please follow best practices and **don't** expose your API KEY in any code you write! \n",
    "\n",
    "You can try this method instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "height": 251
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from aisetup import authenticate, print_llm_response, get_llm_response\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('.env', override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "authenticate(openai_api_key)\n",
    "\n",
    "# Print the LLM response\n",
    "print_llm_response(\"What is the capital of France\")\n",
    "\n",
    "# Store the LLM response as a variable and then print\n",
    "response = print_llm_response(\"What is the capital of France\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pdfminer.six==20250506 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.9/site-packages (from pdfplumber) (11.3.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.9/site-packages (from pdfminer.six==20250506->pdfplumber) (3.3.2)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20250506->pdfplumber)\n",
      "  Downloading cryptography-45.0.7-cp37-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in /usr/local/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
      "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m154.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m162.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-45.0.7-cp37-abi3-manylinux_2_34_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, cryptography, pdfminer.six, pdfplumber\n",
      "Successfully installed cryptography-45.0.7 pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra practice \n",
    "\n",
    "Ask the chatbot for help understanding how the `load_dotenv` code works. Ask for step-by-step instructions on how you can create and setup a `.env` file on your own computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "height": 1526
   },
   "outputs": [],
   "source": [
    "# Step 1: Extract text from PDF\n",
    "def extract_text_from_pdf(pdf_file_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Step 2: Ask LLM to convert PDF text to JSON\n",
    "def pdf_text_to_json(text, required_fields=None):\n",
    "    if required_fields is None:\n",
    "        required_fields = [\"name\", \"address\", \"country\", \"license_number\"]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Extract the following fields from the text and return as JSON:\n",
    "    {', '.join(required_fields)}\n",
    "\n",
    "    Text:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI that converts messy text into structured JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content.strip()\n",
    "    \n",
    "    # Ensure it's valid JSON\n",
    "    try:\n",
    "        data = json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        data = {\"error\": \"Failed to parse JSON\", \"raw_response\": response}\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Step 3: Validate JSON (check missing fields)\n",
    "def validate_json(data, required_fields=None):\n",
    "    if required_fields is None:\n",
    "        required_fields = [\"name\", \"address\", \"country\", \"license_number\"]\n",
    "\n",
    "    missing_fields = [field for field in required_fields if not data.get(field)]\n",
    "    return missing_fields\n",
    "\n",
    "def upload_pdf_file(directory='.'):\n",
    "    \"\"\"\n",
    "    Uploads a PDF file and saves it to the specified directory.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): The directory where the uploaded file will be saved. \n",
    "        Defaults to the current working directory.\n",
    "    \"\"\"\n",
    "    # Create the file upload widget\n",
    "    upload_widget = widgets.FileUpload(\n",
    "        accept='.pdf',  # Accept only PDF files\n",
    "        multiple=False  # Do not allow multiple uploads\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "\n",
    "    # Function to handle file upload\n",
    "    def handle_upload(change):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            file_info = list(upload_widget.value.values())[0]  # Uploaded file info\n",
    "            content = file_info['content']\n",
    "            name = file_info['metadata']['name']\n",
    "            size_in_kb = len(content) / 1024\n",
    "\n",
    "            # File size check (example: 5 MB limit)\n",
    "            if size_in_kb > 5120:\n",
    "                print(\"❌ Your file is too large. Please upload a file under 5MB.\")\n",
    "                return\n",
    "\n",
    "            # Save file to directory\n",
    "            save_path = os.path.join(directory, name)\n",
    "            with open(save_path, 'wb') as f:\n",
    "                f.write(content)\n",
    "\n",
    "            print(f\"✅ The file '{name}' has been uploaded and saved to {directory}.\")\n",
    "\n",
    "    # Attach handler\n",
    "    upload_widget.observe(handle_upload, names='value')\n",
    "\n",
    "    display(upload_widget, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.9/site-packages (8.1.5)\n",
      "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.9/site-packages (0.11.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.9/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.9/site-packages (from ipywidgets) (8.18.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.9/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.9/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.9/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.9/site-packages (from pdfplumber) (20250506)\n",
      "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.9/site-packages (from pdfplumber) (11.3.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.9/site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.9/site-packages (from pdfminer.six==20250506->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.9/site-packages (from pdfminer.six==20250506->pdfplumber) (45.0.7)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.11.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: cffi>=1.14 in /usr/local/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets pdfplumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "height": 370
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1a7db103cf4814841bbec414fb8c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.pdf', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b670fd67ac984359bca1225259ec0e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'uploaded_file.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m pdf_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muploaded_file.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# change this to the actual saved filename\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Step 3: Run the extraction and processing steps\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📜 Extracted Text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, text[:\u001b[38;5;241m500\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# show first 500 characters\u001b[39;00m\n\u001b[1;32m     13\u001b[0m json_data \u001b[38;5;241m=\u001b[39m pdf_text_to_json(text)\n",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m, in \u001b[0;36mextract_text_from_pdf\u001b[0;34m(pdf_file_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text_from_pdf\u001b[39m(pdf_file_path):\n\u001b[1;32m      3\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpdfplumber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_file_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf\u001b[38;5;241m.\u001b[39mpages:\n\u001b[1;32m      6\u001b[0m             text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mextract_text() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pdfplumber/pdf.py:98\u001b[0m, in \u001b[0;36mPDF.open\u001b[0;34m(cls, path_or_fp, pages, laparams, password, strict_metadata, unicode_norm, repair, gs_path, repair_setting, raise_unicode_errors)\u001b[0m\n\u001b[1;32m     96\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_fp, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath)):\n\u001b[0;32m---> 98\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_or_fp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     stream_is_external \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(path_or_fp)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'uploaded_file.pdf'"
     ]
    }
   ],
   "source": [
    "# Step 1: Run this cell to show upload widget and save PDF locally\n",
    "upload_pdf_file()  # This will show the upload widget\n",
    "\n",
    "# Wait for upload, once you see confirmation that \"file has been uploaded and saved...\"\n",
    "\n",
    "# Step 2: Manually provide the uploaded filename here, e.g. 'uploaded_file.pdf'\n",
    "pdf_path = \"uploaded_file.pdf\"  # change this to the actual saved filename\n",
    "\n",
    "# Step 3: Run the extraction and processing steps\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "print(\"\\n📜 Extracted Text:\\n\", text[:500], \"...\")  # show first 500 characters\n",
    "\n",
    "json_data = pdf_text_to_json(text)\n",
    "print(\"\\n📦 Extracted JSON:\\n\", json.dumps(json_data, indent=2))\n",
    "\n",
    "missing = validate_json(json_data)\n",
    "if missing:\n",
    "    print(\"\\n⚠️ Missing fields:\", missing)\n",
    "else:\n",
    "    print(\"\\n✅ All required fields are present.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
